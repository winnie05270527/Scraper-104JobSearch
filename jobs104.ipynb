{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# 查看職缺數量\n",
    "url = 'https://www.104.com.tw/jobs/search/?ro=0&jobcat=2007001004%2C2007001016&expansionType=area%2Cspec%2Ccom%2Cjob%2Cwf%2Cwktm&area=6001001000%2C6001002000&order=16&asc=0&sctp=M&scmin=40000&scstrict=1&scneg=0&page=1&jobexp=1%2C3&mode=s&jobsource=2018indexpoc&langFlag=0&langStatus=0&recommendJob=1&hotJob=1'\n",
    "result = requests.get(url)\n",
    "soup = BeautifulSoup(result.text, 'html.parser')\n",
    "\n",
    "meta_content = soup.find('meta', property='og:description')['content']\n",
    "pattern = r'(\\d+) 個工作機會'\n",
    "match = re.search(pattern, meta_content)\n",
    "jobs_count = match.group(1)\n",
    "\n",
    "# 篩選條件\n",
    "filter_condition = soup.find('meta', property='og:title')['content']\n",
    "print(\"篩選條件:\",filter_condition)\n",
    "print(\"職缺數量:\",jobs_count)\n",
    "\n",
    "\n",
    "# 取得職缺清單\n",
    "job_list = []\n",
    "page_number = 1\n",
    "while True:\n",
    "    url = f'https://www.104.com.tw/jobs/search/?ro=0&jobcat=2007001004%2C2007001016&expansionType=area%2Cspec%2Ccom%2Cjob%2Cwf%2Cwktm&area=6001001000%2C6001002000&order=16&asc=0&sctp=M&scmin=40000&scstrict=1&scneg=0&page={page_number}&jobexp=1%2C3&mode=s&jobsource=2018indexpoc&langFlag=0&langStatus=0&recommendJob=1&hotJob=1'\n",
    "    result = requests.get(url)\n",
    "    soup = BeautifulSoup(result.text, 'html.parser')\n",
    "    \n",
    "    job_items = soup.find_all(\n",
    "        'article', class_='b-block--top-bord job-list-item b-clearfix js-job-item')\n",
    "\n",
    "    if job_items:\n",
    "        pass\n",
    "    else:\n",
    "        page_number -= 1\n",
    "        break\n",
    "        \n",
    "    for item in job_items:\n",
    "        temp = {\n",
    "            'Customer Name': item['data-cust-name'],\n",
    "            'Customer Number': item['data-cust-no'],\n",
    "            'Industry Category': item['data-indcat'],\n",
    "            'Industry Category Description': item['data-indcat-desc'],\n",
    "            'Is Apply': item['data-is-apply'],\n",
    "            'Is Save': item['data-is-save'],\n",
    "            'Job Name': item['data-job-name'],\n",
    "            'Job Number': item['data-job-no'],\n",
    "            'Job RO': item['data-job-ro'],\n",
    "            'Job Source': item['data-jobsource'],\n",
    "            'QA ID': item['data-qa-id'],\n",
    "            'Link': item.find('a', class_='js-job-link')['href'].replace('//', 'https://')\n",
    "        }\n",
    "        job_list.append(temp)\n",
    "    print(\"第\", page_number,\"頁\")\n",
    "    page_number += 1\n",
    "    \n",
    "print(\"Done\", \"頁數:\", page_number, \"筆數:\", len(job_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以職缺連結取得詳細資料\n",
    "jobs_data = []\n",
    "for ind, job_data in enumerate(job_list):\n",
    "    try:\n",
    "        company_name = job_data['Customer Name']\n",
    "        company_category = job_data['Industry Category Description']\n",
    "        job_name = job_data['Job Name']\n",
    "        job_link = job_data['Link']\n",
    "        \n",
    "        job_data = {'公司名稱' : company_name, \n",
    "                    '公司類別' : company_category, \n",
    "                    '職缺名稱' : job_name, \n",
    "                    '職缺連結' : job_link}\n",
    "        \n",
    "        result = requests.get(job_link)\n",
    "        soup = BeautifulSoup(result.text, 'html.parser')\n",
    "\n",
    "        job_descriptions = soup.find(\n",
    "            'p', class_='mb-5 r3 job-description__content text-break').text.replace('\\n', ' ')\n",
    "\n",
    "        job_type = []\n",
    "        for n in soup.findAll('div', {'data-gtm-content': '職務類別'}):\n",
    "            job_type.append(n.text)\n",
    "\n",
    "        job_salary = soup.find('div', class_='list-row row mb-2 identity-type').text.replace(\n",
    "            ' ', '').replace('\\n', '').replace('工作待遇', '')\n",
    "        \n",
    "        \n",
    "        items = soup.findAll('div', class_='list-row row mb-2')\n",
    "        job_details_text = ''\n",
    "        \n",
    "        for item in items[1:]:\n",
    "            job_details_text += item.text + '\\n'\n",
    "\n",
    "\n",
    "        patterns = {\n",
    "            '工作性質': r'工作性質\\s+(.+)',\n",
    "            '上班地點': r'上班地點\\s+(.+)',\n",
    "            '管理責任': r'管理責任\\s+(.+)',\n",
    "            '出差外派': r'出差外派\\s+(.+)',\n",
    "            '上班時段': r'上班時段\\s+(.+)',\n",
    "            '休假制度': r'休假制度\\s+(.+)',\n",
    "            '可上班日': r'可上班日\\s+(.+)',\n",
    "            '需求人數': r'需求人數\\s+(.+)',\n",
    "            '工作經歷': r'工作經歷\\s+(.+)',\n",
    "            '學歷要求': r'學歷要求\\s+(.+)',\n",
    "            '科系要求': r'科系要求\\s+(.+)',\n",
    "            '語文條件': r'語文條件\\s+(.+)',\n",
    "            '擅長工具': r'擅長工具\\s+(.+)',\n",
    "            '工作技能': r'工作技能\\s+(.+)',\n",
    "            '其他條件': r'其他條件\\s+(.+)',\n",
    "        }\n",
    "\n",
    "        temp_data = {key: '' for key in patterns}\n",
    "\n",
    "        for line in job_details_text.split('\\n'):\n",
    "            for key, pattern in patterns.items():\n",
    "                match = re.search(pattern, line)\n",
    "                if match:\n",
    "                    temp_data[key] = match.group(1)\n",
    "\n",
    "\n",
    "        other_conditions = []\n",
    "\n",
    "        in_other_conditions = False\n",
    "\n",
    "        for line in job_details_text.split('\\n'):\n",
    "            if '其他條件' in line:\n",
    "                in_other_conditions = True\n",
    "                continue\n",
    "            if in_other_conditions and line.strip():\n",
    "                other_conditions.append(line.strip())\n",
    "\n",
    "        temp_data['其他條件'] = temp_data['其他條件'] + ' ' + ' '.join(other_conditions)\n",
    "        \n",
    "        job_data.update(temp_data)\n",
    "        jobs_data.append(job_data)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pass\n",
    "        \n",
    "    print(ind+1, job_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將職缺資料存成 Excel 檔案\n",
    "jobs_data_df = pd.DataFrame(jobs_data)\n",
    "jobs_data_df.to_excel('jobs104.xlsx', index=False)\n",
    "print(\"File Saved\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
